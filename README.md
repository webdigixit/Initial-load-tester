# Load Taster ğŸš€

A high-performance HTTP load testing tool that benchmarks your API endpoints under concurrent load. Written in Node.js with parallel request handling and comprehensive performance analytics.

## Features

âœ… **Concurrent Load Testing** â€” Send thousands of HTTP requests in parallel  
âœ… **Real-Time Analytics** â€” Success rate, failure tracking, response time metrics  
âœ… **Performance Insights** â€” Min/max/average response times under load  
âœ… **Timeout Detection** â€” Identify timeout errors and failed requests  
âœ… **JSON Export** â€” Results automatically saved for analysis  
âœ… **Configurable** â€” Easy setup for different endpoints and load levels  

## Installation

### Prerequisites
- Node.js v14+ 
- npm

### Setup

```bash
# Clone the repository
git clone https://github.com/webdigixit/Initial-load-tester.git
cd load-taster

# Install dependencies
npm install
```

## Quick Start

```bash
node index.js
```

**Output:**
```
Start load test...
target: https://your-api.com
requests: 1000
Results
{
  "total": 1000,
  "success": 1000,
  "failed": 0,
  "avgTime": 1249.017,
  "minTime": 1119,
  "maxTime": 1443
}
```

Results automatically saved to `results/last-run.json`

## Configuration

Edit `src/config.js`:

```javascript
module.exports = {
    targetUrl: 'https://your-api.com/endpoint',  // API endpoint to test
    totalRequests: 1000,                          // Number of concurrent requests
    timeout: 10000                                 // Timeout per request (ms)
};
```

## Understanding Results

| Metric | Meaning |
|--------|---------|
| **total** | Total requests sent |
| **success** | Successful requests (HTTP 2xx) |
| **failed** | Failed/timed out requests |
| **avgTime** | Average response time (ms) |
| **minTime** | Fastest response (ms) |
| **maxTime** | Slowest response (ms) |

### Performance Interpretation

| Success Rate | Assessment | Action |
|--------------|-----------|--------|
| **95-100%** | âœ… Excellent | Server handles load well |
| **80-95%** | âš ï¸ Acceptable | Monitor for bottlenecks |
| **<80%** | âŒ Poor | Server overloaded, optimize needed |

## Usage Examples

### Test a Lightweight Endpoint
```javascript
{
    targetUrl: 'https://api.github.com/users/github',
    totalRequests: 100,
    timeout: 5000
}
```

### Stress Test with 5,000 Requests
```javascript
{
    targetUrl: 'https://your-api.com/api/v1/data',
    totalRequests: 5000,
    timeout: 15000
}
```

### Local Development Testing
```javascript
{
    targetUrl: 'http://localhost:3000/api/endpoint',
    totalRequests: 200,
    timeout: 10000
}
```

## Performance Benchmarking

### Step 1: Find the Sweet Spot
Start small and gradually increase load:
- 100 requests â†’ 500 â†’ 1,000 â†’ 2,500 â†’ 5,000

### Step 2: Analyze Results
Track these metrics across test runs:
- Success rate (should stay >95%)
- Average response time (should remain stable)
- Max response time (should not spike)

### Step 3: Identify Limits
```
âœ… 1,000 req â†’ 100% success, 1.2s avg
âš ï¸ 5,000 req â†’ 92% success, 4.5s avg
âŒ 10,000 req â†’ 62% success, 7.7s avg
```
**Conclusion:** Server handles up to ~2,500 requests safely.

## Results Storage

Load test results are saved automatically:
```
results/
â””â”€â”€ last-run.json  // Latest test results
```

Access results:
```bash
cat results/last-run.json
```

## Project Structure

```
load-taster/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js        # Main entry point
â”‚   â”œâ”€â”€ config.js       # Configuration
â”‚   â”œâ”€â”€ runner.js       # Load test orchestrator
â”‚   â”œâ”€â”€ reqester.js     # HTTP request handler
â”‚   â””â”€â”€ stats.js        # Statistics calculator
â”œâ”€â”€ results/
â”‚   â””â”€â”€ last-run.json   # Test results
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Technologies Used

- **axios** â€” HTTP client for reliable requests
- **Node.js** â€” Async/await for parallel execution
- **JavaScript (ES6+)** â€” Modern JavaScript features

## Error Handling

The tool gracefully handles:
- âœ… Network timeouts
- âœ… Connection failures
- âœ… HTTP error responses
- âœ… Large concurrent loads

Failed requests are tracked in the `failed` counter without stopping the test.

## Best Practices

1. **Start Small** â€” Begin with 100â€“500 requests before scaling
2. **Monitor Stability** â€” Run multiple tests and compare results
3. **Realistic Load** â€” Match your expected user concurrency
4. **Timeout Settings** â€” Set timeout > expected response time
5. **Off-Peak Testing** â€” Test during low-traffic hours
6. **REST Between Tests** â€” Allow servers to cool down between runs

## Advanced Usage

### Test Multiple Endpoints
Create different configurations:
```bash
# Test 1: API endpoint
# results/last-run.json saved

# Edit config.js for second endpoint
node index.js

# Compare results manually
```

### Export for Analysis
Results are JSON-formatted and easy to parse:
```bash
# Import into Excel, Python, or analytics tool
cat results/last-run.json | jq
```

## Troubleshooting

**Q: All requests failing?**  
A: Check endpoint URL, network connection, and timeout value.

**Q: Response times spiking?**  
A: Server may be overloaded. Reduce `totalRequests` or check server health.

**Q: Memory issues with large loads?**  
A: Node.js handles parallel requests efficiently. Consider testing in batches.

## Contributing

Contributions welcome! Feel free to:
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ“ Improve documentation

## License

MIT License â€” Free to use and modify

## Author

**WebDigitXIT**  
Load Taster v1.0 - Professional API Load Testing Tool

---

**Made for performance engineers and DevOps teams.** ğŸ¯
